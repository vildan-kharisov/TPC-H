# TPC-H

Цель проекта: получить представление в выявлении узких мест в производительности системы и оптимизации работы с большими объёмами данных. Необходимо получить результат в виде пяти отчетов в базе для сравнения производительности разных систем RDBMS.

TPC-H — это стандартный бенчмарк для тестирования производительности систем управления реляционными базами данных (RDBMS). Он состоит из набора запросов, которые используются для оценки производительности обработки запросов на чтение больших объемов данных из базы данных.

#### Состав проекта: 
- <a href="https://github.com/vildan-kharisov/TPC-H/tree/main/SPARK-job" target="_blank">пять запросов на Spark</a>, объединенных в один DAG Airflow
- <a href="https://github.com/vildan-kharisov/TPC-H/tree/main/Airflow-pipeline" target="_blank">пять запросов на Greenplum</a>, объединенных в один DAG Airflow

#### Задачи, решенные в ходе проекта:
- Спроектировал классическую логическую архитектуру, представленную в DAMA DMBOOK в виде аналитического хранилища (analytical data) и озера данных (data lake);
- Для целей создания технической инфраструктуры использовал следующие технологии:
* Аналитическое хранилище на основе Greenplum;
* Озеро данных на основе технологии S3;
* Распределенные вычисление на основе Spark
* Оркестрация потоков на основе Airflow;
* Хранение исходного кода в GitLab.
- Произвел интеграцию Greenplum и Spark с использованием S3;
- Создал скрипты для Spark Job по обработке данных, полученных с внешних источников в Stage-слое S3;
- Наладил выгрузку, сформировал и заполнил данными хранилище S3 из внешнего источника;
- Сформировал необходимые витрины в Greenplum с помощью технологии Greenplum PXF над отчетами из внешнего хранилища S3;
- В Airflow создал необходимые DAG-и для отправки Spark-задач на кластер, отслеживания задач Spark и их статуса, для выполнения запросов к базе Greenplum;
